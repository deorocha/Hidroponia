# chatbot_ollama.py

import streamlit as st
import requests
import json

# Configura√ß√µes da API
API_URL = "https://api.together.xyz/v1/chat/completions"

# Modelos serverless dispon√≠veis
AVAILABLE_MODELS = {
    "Mistral 7B Instruct": "mistralai/Mistral-7B-Instruct-v0.1",
    "Mixtral 8x7B Instruct": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "Llama 2 70B Chat": "meta-llama/Llama-2-70b-chat-hf",
    "Nous Hermes 2 Mixtral": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "CodeLlama 34B Instruct": "codellama/CodeLlama-34b-Instruct-hf"
}

DEFAULT_MODEL = "mistralai/Mistral-7B-Instruct-v0.1"

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="ChatBot",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'About': None,
        'Get help': None,
        'Report a bug': None
    }
)

st.markdown("""
    <style>
        .block-container {
            margin-top: 1rem;
            padding-top: 0rem;
            padding-bottom: 0rem;
            padding-left: 5rem;
            padding-right: 5rem;
        }
    </style>
    """, unsafe_allow_html=True)

# Ler instru√ß√£o do arquivo
try:
    with open('./chatbot_temas.txt', 'r', encoding='utf-8') as f:
        SYSTEM_INSTRUCTION = f.read()
except Exception as e:
    st.error(f"Erro ao ler instru√ß√µes: {str(e)}")
    SYSTEM_INSTRUCTION = "Voc√™ √© um assistente prestativo."

# API Key
API_KEY = "d5091edfe2b28cc56a5bc0ad8b2743131d7f31631554a91711c1990359d87bf9"

def main():
    if "model_select" not in st.session_state:
        st.session_state.model_select = DEFAULT_MODEL

    # Sidebar para configura√ß√µes
    with st.sidebar:
        st.markdown(f"<h2 style='margin:0; padding:0; margin-top:0; padding-top:0; margin-bottom:0;'>ü§ñ Chatbot</h2>", unsafe_allow_html=True)
        st.markdown("#### ‚öôÔ∏è Configura√ß√µes")
        
        # Seletor de modelo
        selected_model_name = st.selectbox(
            "Selecione o Modelo:",
            options=list(AVAILABLE_MODELS.keys()),
            index=0,
            key="model_selector"
        )
        
        # Atualizar o modelo selecionado na session state
        st.session_state.model_select = AVAILABLE_MODELS[selected_model_name]
        
        # Mostrar qual modelo est√° sendo usado
        st.info(f"Modelo: {selected_model_name}")
        
        # Configura√ß√µes do modelo
        max_tokens = st.slider("Tamanho da resposta", 128, 4096, 1024, key="max_tokens_slider")
        temperature = st.slider("Criatividade", 0.0, 1.0, 0.7, key="temperature_slider")
        top_p = st.slider("Foco", 0.0, 1.0, 0.9, key="top_p_slider")
        
        if st.button("üßπ Limpar hist√≥rico", key="clear_history_btn", use_container_width=True):
            st.session_state.messages = [
                {"role": "assistant", "content": "Hist√≥rico limpo! Como posso ajudar com agricultura ou hidroponia?"}
            ]
            st.rerun()
                
        col1, col2 = st.columns([1, 1])
        with col1:
            if st.button("üëà Voltar", key="btn_back_chatbot", use_container_width=True):
                st.session_state.current_page = "home"
                st.rerun()
        with col2:
            if st.button("üö™ Sair", key="btn_logout_chatbot", use_container_width=True):
                st.session_state.logged_in = False
                st.session_state.user_name = ""
                st.session_state.user_id = None
                st.session_state.current_page = "login"
                st.rerun()

    # Inicializar hist√≥rico de mensagens SEM a instru√ß√£o do sistema no hist√≥rico
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "Ol√°! Sou especialista em agricultura e hidroponia. Como posso ajudar?"}
        ]

    # Exibir hist√≥rico de mensagens
    for message in st.session_state.messages:
        avatar = "ü§ñ" if message["role"] == "assistant" else "üë®‚Äçüåæ"
        with st.chat_message(message["role"], avatar=avatar):
            st.markdown(message["content"])

    # Processar entrada do usu√°rio
    if prompt := st.chat_input("Digite sua mensagem..."):
        # Adicionar mensagem do usu√°rio ao hist√≥rico
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user", avatar="üë®‚Äçüåæ"):
            st.markdown(prompt)
        
        # Gerar resposta
        with st.chat_message("assistant", avatar="ü§ñ"):
            message_placeholder = st.empty()
            full_response = ""
            
            try:
                # Preparar cabe√ßalhos e payload
                headers = {
                    "Authorization": f"Bearer {API_KEY}",
                    "Content-Type": "application/json"
                }
                
                # Preparar mensagens para a API - INCLUIR SYSTEM INSTRUCTION CORRETAMENTE
                api_messages = [
                    {"role": "system", "content": SYSTEM_INSTRUCTION}
                ]
                
                # Adicionar hist√≥rico de conversa (apenas as √∫ltimas 10 mensagens para n√£o exceder o contexto)
                for message in st.session_state.messages[-10:]:
                    api_messages.append(message)
                
                payload = {
                    "model": st.session_state.model_select,
                    "messages": api_messages,
                    "max_tokens": max_tokens,
                    "temperature": temperature,
                    "top_p": top_p,
                    "stream": True,
                    "stop": ["<|eot_id|>", "<|end_of_text|>", "[INST]", "[/INST]"]
                }
                
                # Fazer requisi√ß√£o com streaming
                response = requests.post(
                    API_URL,
                    headers=headers,
                    json=payload,
                    stream=True
                )
                
                # Verificar erros na resposta
                if response.status_code != 200:
                    error = response.json().get("error", {}).get("message", "Erro desconhecido")
                    raise Exception(f"Erro na API ({response.status_code}): {error}")
                
                # Processar streaming de resposta
                for line in response.iter_lines():
                    if line:
                        decoded_line = line.decode('utf-8')
                        if decoded_line.startswith('data: '):
                            json_str = decoded_line[6:]
                            if json_str != '[DONE]':
                                try:
                                    data = json.loads(json_str)
                                    if 'choices' in data and len(data['choices']) > 0:
                                        delta = data['choices'][0].get('delta', {})
                                        if 'content' in delta:
                                            token = delta['content']
                                            full_response += token
                                            message_placeholder.markdown(full_response + "‚ñå")
                                except json.JSONDecodeError:
                                    continue
                
                # Exibir resposta final
                message_placeholder.markdown(full_response)
            
            except Exception as e:
                error_msg = f"‚ö†Ô∏è **Erro na API:** {str(e)}"
                if "401" in str(e):
                    error_msg += "\n\nüîê Verifique sua API Key"
                elif "402" in str(e):
                    error_msg += "\n\nüí≥ Voc√™ pode ter excedido seu cr√©dito gratuito"
                elif "400" in str(e) and "non-serverless" in str(e):
                    error_msg += "\n\nüîß Este modelo requer endpoint dedicado. Tente outro modelo na sidebar."
                elif "rate limit" in str(e).lower():
                    error_msg += "\n\n‚è≥ Limite de requisi√ß√µes excedido, tente novamente mais tarde"
                
                message_placeholder.markdown(error_msg)
                full_response = error_msg
        
        # Adicionar resposta ao hist√≥rico
        st.session_state.messages.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    main()
